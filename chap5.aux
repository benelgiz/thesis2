\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Methodology}{69}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Machine Learning}{69}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Introduction}{69}{subsection.5.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-1}{\ignorespaces Common machine learning methodologies}}{70}{figure.5.1}}
\newlabel{fig:machineLearningMethods}{{5-1}{70}{Common machine learning methodologies}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-2}{\ignorespaces Supervised learning basics }}{71}{figure.5.2}}
\newlabel{fig:supervisedLearningBasics}{{5-2}{71}{Supervised learning basics}{figure.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Machine learning terminology}}{71}{table.5.1}}
\newlabel{arm:machineLearningTerminology}{{5.1}{71}{Machine learning terminology}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Terminology}{71}{subsection.5.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Training set $(\textbf  {x},\textbf  {y})$ of housing prices - one-feature example}}{72}{table.5.2}}
\newlabel{arm:exampHousingPrices}{{5.2}{72}{Training set $(\textbf {x},\textbf {y})$ of housing prices - one-feature example}{table.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Training set $(\textbf  {x},\textbf  {y})$ of housing prices - multi-feature example}}{73}{table.5.3}}
\newlabel{arm:exampleMultiFeatures}{{5.3}{73}{Training set $(\textbf {x},\textbf {y})$ of housing prices - multi-feature example}{table.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Steps towards the learning machine}{73}{subsection.5.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing the data}{73}{section*.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-3}{\ignorespaces Linear regression example - Housing prices as a function of area of the house}}{74}{figure.5.3}}
\newlabel{fig:housingPrices}{{5-3}{74}{Linear regression example - Housing prices as a function of area of the house}{figure.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-4}{\ignorespaces Classification example}}{75}{figure.5.4}}
\newlabel{fig:classificationEx2}{{5-4}{75}{Classification example}{figure.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-5}{\ignorespaces Classification example}}{76}{figure.5.5}}
\newlabel{fig:classificationEx1}{{5-5}{76}{Classification example}{figure.5.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Mapping}{76}{section*.15}}
\newlabel{eqn:costFuncExamp1}{{5.1}{76}{Feature Mapping}{equation.5.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-6}{\ignorespaces Classification example}}{77}{figure.5.6}}
\newlabel{fig:classificationEx3}{{5-6}{77}{Classification example}{figure.5.6}{}}
\newlabel{eqn:featureMapping1}{{5.2}{77}{Feature Mapping}{equation.5.1.2}{}}
\newlabel{eqn:featureMapping2}{{5.3}{77}{Feature Mapping}{equation.5.1.3}{}}
\newlabel{eqn:featureMapping3}{{5.4}{78}{Feature Mapping}{equation.5.1.4}{}}
\newlabel{eqn:featureMapping4}{{5.5}{78}{Feature Mapping}{equation.5.1.5}{}}
\newlabel{eqn:featureMappin54}{{5.6}{78}{Feature Mapping}{equation.5.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Selecting Model Structure}{78}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-7}{\ignorespaces Complex decision boundary}}{79}{figure.5.7}}
\newlabel{fig:complexBoundary}{{5-7}{79}{Complex decision boundary}{figure.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-8}{\ignorespaces Guide for feature mapping}}{80}{figure.5.8}}
\newlabel{fig:ml_followChart}{{5-8}{80}{Guide for feature mapping}{figure.5.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-9}{\ignorespaces Guide for feature mapping}}{81}{figure.5.9}}
\newlabel{fig:modelSelection}{{5-9}{81}{Guide for feature mapping}{figure.5.9}{}}
\newlabel{eqn:costFuncCrossVal}{{5.7}{82}{Selecting Model Structure}{equation.5.1.7}{}}
\newlabel{eqn:costFuncTest}{{5.8}{82}{Selecting Model Structure}{equation.5.1.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{Scaling}{83}{section*.17}}
\newlabel{eqn:scalingFeatures}{{5.9}{83}{Scaling}{equation.5.1.9}{}}
\newlabel{eqn:meandAndRange}{{5.10}{83}{Scaling}{equation.5.1.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{Add Artificial Feature}{83}{section*.18}}
\newlabel{eqn:featureVector}{{5.11}{83}{Add Artificial Feature}{equation.5.1.11}{}}
\newlabel{eqn:parameterVector}{{5.12}{83}{Add Artificial Feature}{equation.5.1.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-10}{\ignorespaces Adding an artificial feature of 1s.}}{84}{figure.5.10}}
\newlabel{fig:addArtificialFeature}{{5-10}{84}{Adding an artificial feature of 1s}{figure.5.10}{}}
\newlabel{eqn:costFuncOneFeature}{{5.13}{84}{Add Artificial Feature}{equation.5.1.13}{}}
\newlabel{eqn:costFuncMltplFeature}{{5.14}{84}{Add Artificial Feature}{equation.5.1.14}{}}
\newlabel{eqn:costFuncMltplFeature}{{5.15}{84}{Add Artificial Feature}{equation.5.1.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Selection of the Cost Function and Calculating the Gradient }{84}{section*.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-11}{\ignorespaces Guide for feature mapping}}{85}{figure.5.11}}
\newlabel{fig:underOverFit}{{5-11}{85}{Guide for feature mapping}{figure.5.11}{}}
\newlabel{eqn:costFuncLinearRegression}{{5.16}{85}{Selection of the Cost Function and Calculating the Gradient}{equation.5.1.16}{}}
\newlabel{eqn:costFuncLogisticRegression}{{5.17}{85}{Selection of the Cost Function and Calculating the Gradient}{equation.5.1.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Modify the Cost Function by Adding Regularization Term}{85}{section*.20}}
\newlabel{eqn:featureMapping2}{{5.18}{85}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.18}{}}
\newlabel{eqn:costFuncTest}{{5.19}{86}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.19}{}}
\newlabel{eqn:costFuncLogisticRegressionModified}{{5.20}{86}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.20}{}}
\newlabel{eqn:errorMisclassificationError}{{5.21}{86}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-12}{\ignorespaces Procedure to detect overfitting}}{87}{figure.5.12}}
\newlabel{fig:overfittingRealization}{{5-12}{87}{Procedure to detect overfitting}{figure.5.12}{}}
\newlabel{eqn:misclassificationError}{{5.22}{87}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.22}{}}
\newlabel{eqn:costFuncRegularized}{{5.23}{87}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.23}{}}
\newlabel{eqn:costFuncRegularizedTooMuch}{{5.24}{88}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.24}{}}
\newlabel{eqn:costFuncRegularizedTooMuchHow}{{5.25}{88}{Modify the Cost Function by Adding Regularization Term}{equation.5.1.25}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cost Function Minimization}{88}{section*.21}}
\newlabel{eqn:optimizationGoal}{{5.26}{88}{Cost Function Minimization}{equation.5.1.26}{}}
\newlabel{eqn:linearRegressionTwoFeaturesSummary}{{5.27}{88}{Cost Function Minimization}{equation.5.1.27}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gradient Descent for one feature only}}{89}{algorithm.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Gradient Descent in a general sense}}{90}{algorithm.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-13}{\ignorespaces Gradient descent convergence dependance on $theta_init$. Two different but close choice of $theta_init$ might converge to local or global minima }}{90}{figure.5.13}}
\newlabel{fig:localOrGlobalMinimaGD}{{5-13}{90}{Gradient descent convergence dependance on $theta_init$. Two different but close choice of $theta_init$ might converge to local or global minima}{figure.5.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-14}{\ignorespaces Evolution of $J(\theta )$ with respect to number of iterations. Left two figures showing that the optimization problem is not converging. The figure in the far right is the $J(\theta )$ evolution expected}}{91}{figure.5.14}}
\newlabel{fig:visualizeCostFunc}{{5-14}{91}{Evolution of $J(\theta )$ with respect to number of iterations. Left two figures showing that the optimization problem is not converging. The figure in the far right is the $J(\theta )$ evolution expected}{figure.5.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing the cost function}{91}{section*.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-15}{\ignorespaces Diagnosis the problem of machine learning by comparing the cost function for the training and cross-validation data sets}}{93}{figure.5.15}}
\newlabel{fig:debuggingHypothesis}{{5-15}{93}{Diagnosis the problem of machine learning by comparing the cost function for the training and cross-validation data sets}{figure.5.15}{}}
\citation{gunn1998support}
\citation{yin2014study}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing the model/classifier (decision boundary) with respect to training data}{94}{section*.23}}
\@writefile{toc}{\contentsline {subsubsection}{Prediction}{94}{section*.24}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Support Vector Machines}{94}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Introduction}{94}{subsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-16}{\ignorespaces SVM working principle}}{95}{figure.5.16}}
\newlabel{fig:svmHyperplane}{{5-16}{95}{SVM working principle}{figure.5.16}{}}
\citation{platt1999probabilistic}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Application}{97}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{Training of the classifier}{97}{section*.25}}
\citation{platt1998sequential}
\@writefile{toc}{\contentsline {subsubsection}{Tuning of the classifier}{99}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-17}{\ignorespaces Convergence of minimum objective function}}{100}{figure.5.17}}
\newlabel{fig:objectiveFuncEval}{{5-17}{100}{Convergence of minimum objective function}{figure.5.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-18}{\ignorespaces Objective function values for different box parameter and sigma values}}{101}{figure.5.18}}
\newlabel{fig:objFuncModel}{{5-18}{101}{Objective function values for different box parameter and sigma values}{figure.5.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-19}{\ignorespaces Objective function values for different box parameter and sigma values}}{102}{figure.5.19}}
\newlabel{fig:objFuncModel}{{5-19}{102}{Objective function values for different box parameter and sigma values}{figure.5.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-20}{\ignorespaces Objective function values for different box parameter and sigma values}}{103}{figure.5.20}}
\newlabel{fig:objFuncModel}{{5-20}{103}{Objective function values for different box parameter and sigma values}{figure.5.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-21}{\ignorespaces Objective function values for different box parameter and sigma values}}{104}{figure.5.21}}
\newlabel{fig:objFuncModel}{{5-21}{104}{Objective function values for different box parameter and sigma values}{figure.5.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluating the classifier}{105}{section*.27}}
\newlabel{evalClassifier}{{5.2.2}{105}{Evaluating the classifier}{section*.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5-22}{\ignorespaces Confusion matrix}}{107}{figure.5.22}}
\newlabel{fig:confusionMatrix}{{5-22}{107}{Confusion matrix}{figure.5.22}{}}
\@setckpt{chap5}{
\setcounter{page}{108}
\setcounter{equation}{35}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{2}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{22}
\setcounter{table}{3}
\setcounter{savepage}{3}
\setcounter{Item}{10}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{47}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{dirtytalk@qdepth}{0}
\setcounter{nlinenum}{0}
\setcounter{r@tfl@t}{0}
\setcounter{float@type}{16}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{3}
\setcounter{lstlisting}{0}
}
